{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email classification based on Bayesian analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # I/O\n",
    "import re  # regular expression\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing and CSV file I/O\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # split train and test\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "RANDOM_SEED = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Show datasets in project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Data\\SMSSpamCollection\n",
      ".\\Data\\spam_ham_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk(f'.\\Data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to run one of cells following. If you want to use other Datasets, you should organize your dataset to include at least 'text' and 'label_num' as in 'spam_ham_dataset.csv'. If not, as 1.2.2. DataSet2, you should add 'text' and 'label_num' by yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. DataSet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3  spam  Subject: photoshop , windows , office . cheap ...          1\n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...          0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(f'.\\Data\\spam_ham_dataset.csv')\n",
    "df.drop([df.columns[0]], axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. DataSet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/SMSSpamCollection',sep='\\t')\n",
    "df.head()\n",
    "label = []\n",
    "for w in range(len(df.text)):\n",
    "    if df['label'][w] == 'ham':\n",
    "        label.append(0)\n",
    "    else:\n",
    "        label.append(1)\n",
    "df['label_num'] = label\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    #remove punctuation\n",
    "    desc = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    #remove tags\n",
    "    desc = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",desc)\n",
    "    #remove digits and special chars\n",
    "    desc = re.sub(\"(\\\\d|\\\\W)+\",\" \",desc) \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject enron methanol meter this is a follow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject hpl nom for january see attached file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject neon retreat ho ho ho we re around to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject photoshop windows office cheap main tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re indian springs this deal is to book...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num  \\\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0   \n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0   \n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0   \n",
       "3  spam  Subject: photoshop , windows , office . cheap ...          1   \n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...          0   \n",
       "\n",
       "                                               clean  \n",
       "0  subject enron methanol meter this is a follow ...  \n",
       "1  subject hpl nom for january see attached file ...  \n",
       "2  subject neon retreat ho ho ho we re around to ...  \n",
       "3  subject photoshop windows office cheap main tr...  \n",
       "4  subject re indian springs this deal is to book...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_txt = []\n",
    "for w in range(len(df.text)):\n",
    "   text = df['text'][w].lower()\n",
    "   desc = clean_data(text)\n",
    "   clean_txt.append(desc)\n",
    "df['clean'] = clean_txt\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Split Training data and Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer** is a great tool provided by the scikit-learn library in Python. It is used to transform a given text into a **vector on the basis of the frequency (count) of each word** that occurs in the entire text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, label_train, label_test = train_test_split(df['clean'], df['label_num'], test_size=0.2, random_state=RANDOM_SEED)\n",
    "vectorizer_text = CountVectorizer(max_df=0.9, min_df=10)   \n",
    "x_train = vectorizer_text.fit_transform(text_train)\n",
    "x_test = vectorizer_text.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Build in implementation and it's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB()\n",
      "accuracy: 0.9101, precision: 0.8632, recall: 0.8200\n",
      "MultinomialNB()\n",
      "accuracy: 0.9507, precision: 0.8807, recall: 0.9600\n",
      "ComplementNB()\n",
      "accuracy: 0.9527, precision: 0.8815, recall: 0.9667\n"
     ]
    }
   ],
   "source": [
    "for NB in [BernoulliNB(), MultinomialNB(), ComplementNB()]:\n",
    "    NB.fit(x_train, label_train)\n",
    "    p_test = NB.predict(x_test)\n",
    "    test_acc = accuracy_score(label_test, p_test)        # accuracy\n",
    "    test_precision = precision_score(label_test, p_test) # (spam and label as spam)/(labeled as spam)\n",
    "    test_recall = recall_score(label_test, p_test)       # (spam and label as spam)/(all spam)\n",
    "    print(NB)\n",
    "    print('accuracy: {:.4f}, precision: {:.4f}, recall: {:.4f}'.format(test_acc, test_precision, test_recall)) # print performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Our Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, label_train):\n",
    "    x_data = x_train.toarray()\n",
    "    m,n = x_data.shape\n",
    "    spam_num = len(label_train[label_train==1])\n",
    "    ham_num = m - spam_num\n",
    "    p_spam = spam_num/len(label_train)\n",
    "    \n",
    "    p_spam_cond = np.zeros(n)\n",
    "    p_ham_cond = np.zeros(n)\n",
    "    p_x = np.zeros(n)\n",
    "    for j in range(n):\n",
    "        for i in range(m):\n",
    "            if x_data[i,j]>0:\n",
    "                p_x[j] = p_x[j]+1/m\n",
    "                if label_train[i]==1:\n",
    "                    p_spam_cond[j] = p_spam_cond[j]+1/spam_num\n",
    "                if label_train[i]==0:\n",
    "                    p_ham_cond[j] = p_ham_cond[j]+1/ham_num\n",
    "    p_ham_cond[p_ham_cond==0]=0.0001\n",
    "    p_spam_cond[p_spam_cond==0]=0.0001\n",
    "    return (p_spam, p_spam_cond, p_ham_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test, p_spam, p_spam_cond, p_ham_cond):\n",
    "    m,n = x_test.shape\n",
    "    label_pre = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        px_spam = p_spam\n",
    "        px_ham = 1-p_spam\n",
    "        for j in range(len(p_spam_cond)):\n",
    "            if x_test[i,j]>0:\n",
    "                px_spam = px_spam*p_spam_cond[j]\n",
    "                px_ham = px_ham*p_ham_cond[j]\n",
    "        label_pre[i] = int(px_spam>=px_ham)\n",
    "    return label_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam, p_spam_cond, p_ham_cond = fit(x_train, label_train.values)\n",
    "label_pre = predict(x_test, p_spam, p_spam_cond, p_ham_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9353, precision: 0.8416, recall: 0.9567\n"
     ]
    }
   ],
   "source": [
    "test_acc = accuracy_score(label_test, label_pre)\n",
    "test_precision = precision_score(label_test, label_pre)\n",
    "test_recall = recall_score(label_test, label_pre)\n",
    "print('accuracy: {:.4f}, precision: {:.4f}, recall: {:.4f}'.format(test_acc, test_precision, test_recall)) # print performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Example of our mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Please paste your email content here!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = '''\n",
    "Better English handwriting support\n",
    "We are delighted to announce improvements to our English handwriting recognition. We used spell check and word frequency information to bias the algorithm towards more likely words when our algorithm is uncertain. For example, take this input image:\n",
    "\n",
    "Before spell check:\n",
    "\n",
    "Dolution:\n",
    "Ans 24). In developing a chart to flot a course of action, with many of the events or milestones, we will we Process deciscon pirogram chart.\n",
    "so, optison (A) is cossect ansuver.\n",
    "\n",
    "After spell check:\n",
    "\n",
    "Solution:\n",
    "Ans 24). In developing a chart to plot a course of action, with many of the events or milestones, we will we Process decision program chart.\n",
    "so, option (A) is correct answer.\n",
    "\n",
    "Notice the big improvement! The spelling-aware improvements are only live for English and have no impact on other languages. These improvements will be coming soon for Spanish, French, and German.\n",
    "\n",
    "Please note that incorrectly spelled words that are clearly written will not be changed: this predictive mode is only enabled when the underlying handwritten word is visually ambiguous.\n",
    "Better English handwriting support\n",
    "You can now select text directly from an opened PDF in the Snip web app. You can hover over a piece of text or math and click the clipboard button to copy the Markdown to your clipboard:\n",
    "\n",
    "You can also click and drag to highlight the region of interest or double click any section to get access to selectable and copyable text:\n",
    "\n",
    "\n",
    "You can use this feature on printed and handwritten PDFs:\n",
    "\n",
    "\n",
    "Scribe: human-powered document conversion\n",
    "AI has become very powerful at converting PDFs and images to editable text. But it’s still not perfect, and probably never will be (although we are getting closer day by day!).\n",
    "\n",
    "To alleviate the gap, we are now offering human-powered services for document conversion that combine our AI with human LaTeX experts, so that you can get a perfect translation of your document to your desired format.\n",
    "\n",
    "Simply send your PDF to scribe@mathpix.com with any special instructions on what you need and when you need it converted by. You can accept our standard price of $5 per input page, or request a discount if, for example, there is low text density per page. We then charge your card or payment method on file at accounts.mathpix.com.\n",
    "\n",
    "This service is ideal for lecture notes (including handwritten ones) or older documents that you want to have perfectly transcribed.\n",
    "\n",
    "More information about our Scribe service is available on our website.\n",
    "Spectra writing competition update\n",
    "We are extending the current Spectra writing competition deadline to January 1st. We will pick just 3 winners, with cash prizes of $2K for each winner. We will rank the winners as in previous competitions. More improvements to Spectra are coming soon.\n",
    "\n",
    "We are also still giving away the yearly Pro plan for free to all those that submit content!\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’s a spam email!\n"
     ]
    }
   ],
   "source": [
    "# No input needed!\n",
    "spam = clean_data(spam)\n",
    "x = vectorizer_text.transform(np.array([spam]))\n",
    "label_pre = predict(x, p_spam, p_spam_cond, p_ham_cond)\n",
    "if label_pre == 1:\n",
    "    print('It’s a spam email!')\n",
    "else:\n",
    "    print('It’s a ham email!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5ff168696553f3e2cb115c273c46eeb315c32b0d0536992c4bad2740a7f9469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
